{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast, Trainer, RobertaForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import matplotlib\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:.6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam feels happy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam feels ecstatic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam feels glad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam feels relieved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam feels excited.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>The conversation with Jack was funny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>The conversation with Jack was hilarious.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>The conversation with Jack was amazing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>The conversation with Jack was wonderful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>The conversation with Jack was great.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text\n",
       "0                            Adam feels happy.\n",
       "1                         Adam feels ecstatic.\n",
       "2                             Adam feels glad.\n",
       "3                         Adam feels relieved.\n",
       "4                          Adam feels excited.\n",
       "..                                         ...\n",
       "345      The conversation with Jack was funny.\n",
       "346  The conversation with Jack was hilarious.\n",
       "347    The conversation with Jack was amazing.\n",
       "348  The conversation with Jack was wonderful.\n",
       "349      The conversation with Jack was great.\n",
       "\n",
       "[350 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_female_angry_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_angry_AA.csv')\n",
    "df_female_fear_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_fear_AA.csv')\n",
    "df_female_joy_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_joy_AA.csv')\n",
    "df_female_sadness_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_sadness_AA.csv')\n",
    "df_male_angry_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_angry_AA.csv')\n",
    "df_male_fear_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_fear_AA.csv')\n",
    "df_male_joy_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_joy_AA.csv')\n",
    "df_male_sadness_AA = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_sadness_AA.csv')\n",
    "df_female_angry_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_angry_E.csv')\n",
    "df_female_fear_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_fear_E.csv')\n",
    "df_female_joy_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_joy_E.csv')\n",
    "df_female_sadness_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_sadness_E.csv')\n",
    "df_male_angry_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_angry_E.csv')\n",
    "df_male_fear_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_fear_E.csv')\n",
    "df_male_joy_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_joy_E.csv')\n",
    "df_male_sadness_E = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_sadness_E.csv')\n",
    "df_female_AA_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_AA_non_emotion.csv')\n",
    "df_male_AA_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_AA_non_emotion.csv')\n",
    "df_female_E_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_E_non_emotion.csv')\n",
    "df_male_E_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_E_non_emotion.csv')\n",
    "df_female_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_non_emotion.csv')\n",
    "df_male_non_emotion = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_non_emotion.csv')\n",
    "df_female_angry_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_angry_non_race.csv')\n",
    "df_female_fear_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_fear_non_race.csv')\n",
    "df_female_joy_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_joy_non_race.csv')\n",
    "df_female_sadness_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_female_sadness_non_race.csv')\n",
    "df_male_angry_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_angry_non_race.csv')\n",
    "df_male_fear_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_fear_non_race.csv')\n",
    "df_male_joy_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_joy_non_race.csv')\n",
    "df_male_sadness_non_race = pd.read_csv(f'../../Data/EEC/Equity-Evaluation-Corpus/df_male_sadness_non_race.csv')\n",
    "\n",
    "\n",
    "df_male_joy_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def data_prep(df):\n",
    "    return Dataset.from_pandas(df).map(tokenize_function, batched=True)\n",
    "\n",
    "df_female_angry_AA = data_prep(df_female_angry_AA)\n",
    "df_female_fear_AA = data_prep(df_female_fear_AA)\n",
    "df_female_joy_AA = data_prep(df_female_joy_AA)\n",
    "df_female_sadness_AA = data_prep(df_female_sadness_AA)\n",
    "df_male_angry_AA = data_prep(df_male_angry_AA)\n",
    "df_male_fear_AA = data_prep(df_male_fear_AA)\n",
    "df_male_joy_AA = data_prep(df_male_joy_AA)\n",
    "df_male_sadness_AA = data_prep(df_male_sadness_AA)\n",
    "df_female_angry_E = data_prep(df_female_angry_E)\n",
    "df_female_fear_E = data_prep(df_female_fear_E)\n",
    "df_female_joy_E = data_prep(df_female_joy_E)\n",
    "df_female_sadness_E = data_prep(df_female_sadness_E)\n",
    "df_male_angry_E = data_prep(df_male_angry_E)\n",
    "df_male_fear_E = data_prep(df_male_fear_E)\n",
    "df_male_joy_E = data_prep(df_male_joy_E)\n",
    "df_male_sadness_E = data_prep(df_male_sadness_E)\n",
    "df_female_AA_non_emotion = data_prep(df_female_AA_non_emotion)\n",
    "df_male_AA_non_emotion = data_prep(df_male_AA_non_emotion)\n",
    "df_female_E_non_emotion = data_prep(df_female_E_non_emotion)\n",
    "df_male_E_non_emotion = data_prep(df_male_E_non_emotion)\n",
    "df_female_non_emotion = data_prep(df_female_non_emotion)\n",
    "df_male_non_emotion = data_prep(df_male_non_emotion)\n",
    "df_female_angry_non_race = data_prep(df_female_angry_non_race)\n",
    "df_female_fear_non_race = data_prep(df_female_fear_non_race)\n",
    "df_female_joy_non_race = data_prep(df_female_joy_non_race)\n",
    "df_female_sadness_non_race = data_prep(df_female_sadness_non_race)\n",
    "df_male_angry_non_race = data_prep(df_male_angry_non_race)\n",
    "df_male_fear_non_race = data_prep(df_male_fear_non_race)\n",
    "df_male_joy_non_race = data_prep(df_male_joy_non_race)\n",
    "df_male_sadness_non_race = data_prep(df_male_sadness_non_race)\n",
    "\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_compare(set_name, male_set, female_set):    \n",
    "    predictions_male = trainer.predict(male_set)\n",
    "    predictions_female = trainer.predict(female_set)\n",
    "\n",
    "    preds_male = predictions_male.predictions.argmax(-1)\n",
    "    scores_male = (np.exp(predictions_male[0])/np.exp(predictions_male[0]).sum(-1,keepdims=True)).max(1)\n",
    "\n",
    "    preds_female = predictions_female.predictions.argmax(-1)\n",
    "    scores_female = (np.exp(predictions_female[0])/np.exp(predictions_female[0]).sum(-1,keepdims=True)).max(1)\n",
    "\n",
    "    df = pd.DataFrame(list(zip(preds_male, preds_female, scores_male, scores_female)), columns=['pred_male', 'pred_female' ,'score_male', 'score_female'])\n",
    "    df['Match'] = df['pred_male'] == df['pred_female']\n",
    "    value_counts = df['Match'].value_counts()\n",
    "    print(f'Comparison Set - {set_name}')\n",
    "    print('The model counts for predicting the same label for each gender:')\n",
    "    try: \n",
    "        print(f'True: {value_counts[True]}')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f'False: {value_counts[False]}')\n",
    "    except:\n",
    "        pass\n",
    "    df = df[df['Match']==True]\n",
    "    df['diff'] = abs(df['score_male'] - df['score_female'])\n",
    "    df_sig = df[df['diff'] > 0]\n",
    "    df_nonsig = df[df['diff'] == 0]\n",
    "    print(f'The total number of records with same predicted label: {len(df.index)}')\n",
    "    print(f'The model predicted the same value for this many records: {len(df_nonsig.index)}')\n",
    "    print(f'The model predicted a different value for this many records: {len(df_sig.index)}')\n",
    "    print(f\"Male average: {df_sig.describe().loc['mean', 'score_male']}\")\n",
    "    print(f\"Female average: {df_sig.describe().loc['mean', 'score_female']}\")\n",
    "    print(f\"Average difference: {df_sig.describe().loc['mean', 'diff']}\")\n",
    "    print('-'*25)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_compare(set_name, AA_set, E_set):    \n",
    "    predictions_AA = trainer.predict(AA_set)\n",
    "    predictions_E = trainer.predict(E_set)\n",
    "\n",
    "    preds_AA = predictions_AA.predictions.argmax(-1)\n",
    "    scores_AA = (np.exp(predictions_AA[0])/np.exp(predictions_AA[0]).sum(-1,keepdims=True)).max(1)\n",
    "\n",
    "    preds_E = predictions_E.predictions.argmax(-1)\n",
    "    scores_E = (np.exp(predictions_E[0])/np.exp(predictions_E[0]).sum(-1,keepdims=True)).max(1)\n",
    "\n",
    "    df = pd.DataFrame(list(zip(preds_AA, preds_E, scores_AA, scores_E)), columns=['pred_AA', 'pred_E' ,'score_AA', 'score_E'])\n",
    "\n",
    "    df['Match'] = df['pred_AA'] == df['pred_E']\n",
    "    value_counts = df['Match'].value_counts()\n",
    "    print(f'Comparison Set - {set_name}')\n",
    "    print('The model counts for predicting the same label for each race:')\n",
    "    try: \n",
    "        print(f'True: {value_counts[True]}')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f'False: {value_counts[False]}')\n",
    "    except:\n",
    "        pass    \n",
    "    df = df[df['Match']==True]\n",
    "    df['diff'] = abs(df['score_AA'] - df['score_E'])\n",
    "    df_sig = df[df['diff'] > 0]\n",
    "    df_nonsig = df[df['diff'] == 0]\n",
    "    print(f'The total number of records with same predicted label: {len(df.index)}')\n",
    "    print(f'The model predicted the same value for this many records: {len(df_nonsig.index)}')\n",
    "    print(f'The model predicted a different value for this many records: {len(df_sig.index)}')\n",
    "    print(f\"African-American average: {df_sig.describe().loc['mean', 'score_AA']}\")\n",
    "    print(f\"European average: {df_sig.describe().loc['mean', 'score_E']}\")\n",
    "    print(f\"Average difference: {df_sig.describe().loc['mean', 'diff']}\")\n",
    "    print('-'*25)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 3/44 [00:21<05:12,  7.62s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gender_compare(\u001b[39m'\u001b[39;49m\u001b[39mangry_AA\u001b[39;49m\u001b[39m'\u001b[39;49m, df_male_angry_AA, df_female_angry_AA)\n\u001b[0;32m      2\u001b[0m gender_compare(\u001b[39m'\u001b[39m\u001b[39mfear_AA\u001b[39m\u001b[39m'\u001b[39m, df_male_fear_AA, df_female_fear_AA)\n\u001b[0;32m      3\u001b[0m gender_compare(\u001b[39m'\u001b[39m\u001b[39mjoy_AA\u001b[39m\u001b[39m'\u001b[39m, df_male_joy_AA, df_female_joy_AA)\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mgender_compare\u001b[1;34m(set_name, male_set, female_set)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgender_compare\u001b[39m(set_name, male_set, female_set):    \n\u001b[1;32m----> 2\u001b[0m     predictions_male \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mpredict(male_set)\n\u001b[0;32m      3\u001b[0m     predictions_female \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(female_set)\n\u001b[0;32m      5\u001b[0m     preds_male \u001b[39m=\u001b[39m predictions_male\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:3069\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3066\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3068\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3069\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[0;32m   3070\u001b[0m     test_dataloader, description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPrediction\u001b[39;49m\u001b[39m\"\u001b[39;49m, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix\n\u001b[0;32m   3071\u001b[0m )\n\u001b[0;32m   3072\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[0;32m   3073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:3174\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3171\u001b[0m         batch_size \u001b[39m=\u001b[39m observed_batch_size\n\u001b[0;32m   3173\u001b[0m \u001b[39m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 3174\u001b[0m loss, logits, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys)\n\u001b[0;32m   3175\u001b[0m inputs_decode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39minclude_inputs_for_metrics \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3177\u001b[0m \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:3439\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   3437\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3438\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3439\u001b[0m     outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   3440\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m):\n\u001b[0;32m   3441\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m outputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ignore_keys)\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1216\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[0;32m   1217\u001b[0m     input_ids,\n\u001b[0;32m   1218\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1219\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1220\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1221\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1222\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1223\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1224\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1225\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1228\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    843\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    845\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    846\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    847\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    850\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    851\u001b[0m )\n\u001b[1;32m--> 852\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    853\u001b[0m     embedding_output,\n\u001b[0;32m    854\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    855\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    856\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    857\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    858\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    859\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    860\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    861\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    862\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    863\u001b[0m )\n\u001b[0;32m    864\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    865\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    520\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    528\u001b[0m         hidden_states,\n\u001b[0;32m    529\u001b[0m         attention_mask,\n\u001b[0;32m    530\u001b[0m         layer_head_mask,\n\u001b[0;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    533\u001b[0m         past_key_value,\n\u001b[0;32m    534\u001b[0m         output_attentions,\n\u001b[0;32m    535\u001b[0m     )\n\u001b[0;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:411\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    400\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    401\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    409\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    412\u001b[0m         hidden_states,\n\u001b[0;32m    413\u001b[0m         attention_mask,\n\u001b[0;32m    414\u001b[0m         head_mask,\n\u001b[0;32m    415\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    416\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    417\u001b[0m     )\n\u001b[0;32m    418\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    420\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:338\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    330\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 338\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    339\u001b[0m         hidden_states,\n\u001b[0;32m    340\u001b[0m         attention_mask,\n\u001b[0;32m    341\u001b[0m         head_mask,\n\u001b[0;32m    342\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    343\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    344\u001b[0m         past_key_value,\n\u001b[0;32m    345\u001b[0m         output_attentions,\n\u001b[0;32m    346\u001b[0m     )\n\u001b[0;32m    347\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    348\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nadee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:274\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     attention_probs \u001b[39m=\u001b[39m attention_probs \u001b[39m*\u001b[39m head_mask\n\u001b[1;32m--> 274\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attention_probs, value_layer)\n\u001b[0;32m    276\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    277\u001b[0m new_context_layer_shape \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size,)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gender_compare('angry_AA', df_male_angry_AA, df_female_angry_AA)\n",
    "gender_compare('fear_AA', df_male_fear_AA, df_female_fear_AA)\n",
    "gender_compare('joy_AA', df_male_joy_AA, df_female_joy_AA)\n",
    "gender_compare('sadness_AA', df_male_sadness_AA, df_female_sadness_AA)\n",
    "\n",
    "gender_compare('angry_E', df_male_angry_E, df_female_angry_E)\n",
    "gender_compare('fear_E', df_male_fear_E, df_female_fear_E)\n",
    "gender_compare('joy_E', df_male_joy_E, df_female_joy_E)\n",
    "gender_compare('sadness_E', df_male_sadness_E, df_female_sadness_E)\n",
    "\n",
    "gender_compare('non-emotion_AA', df_male_AA_non_emotion, df_female_AA_non_emotion)\n",
    "gender_compare('non-emotion_E', df_male_E_non_emotion, df_female_E_non_emotion)\n",
    "gender_compare('non-emotion_non-race', df_male_non_emotion, df_female_non_emotion)\n",
    "\n",
    "gender_compare('angry_non-race', df_male_angry_non_race, df_female_angry_non_race)\n",
    "gender_compare('fear_non-race', df_male_fear_non_race, df_female_fear_non_race)\n",
    "gender_compare('joy_non-race', df_male_joy_non_race, df_female_joy_non_race)\n",
    "gender_compare('sadness_non-race', df_male_sadness_non_race, df_female_sadness_non_race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24eacde111e04158b8bcc8a689ac8875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc3142f64cb434ab5818a2fefa6cd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - angry_male\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 347\n",
      "False: 3\n",
      "The total number of records with same predicted label: 347\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 347\n",
      "African-American average: 0.9854414463043213\n",
      "European average: 0.9789865016937256\n",
      "Average difference: 0.009361729957163334\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d19463d5b64e208f238186e20aceb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af89ab0a61049af85e582dfc55510e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - fear_male\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 346\n",
      "False: 4\n",
      "The total number of records with same predicted label: 346\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 346\n",
      "African-American average: 0.9792342782020569\n",
      "European average: 0.9776576161384583\n",
      "Average difference: 0.012603932991623878\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3b833f5c1a4b86a5cd23e66481eb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0641296c11434211be55342c8a33f49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - joy_male\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 350\n",
      "The total number of records with same predicted label: 350\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 350\n",
      "African-American average: 0.9778149127960205\n",
      "European average: 0.9844175577163696\n",
      "Average difference: 0.008992256596684456\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721e5a85e32d49cd893edfaf17e075e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65c64f5b22d48ad915821417d463e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - sadness_male\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 350\n",
      "The total number of records with same predicted label: 350\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 350\n",
      "African-American average: 0.9921132326126099\n",
      "European average: 0.9914563894271851\n",
      "Average difference: 0.003664857940748334\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178900bded284d97a2e6c596ed2b11fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509d993f58bb441f85bfb863af3cdf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - angry_female\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 350\n",
      "The total number of records with same predicted label: 350\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 350\n",
      "African-American average: 0.9870122671127319\n",
      "European average: 0.9855170845985413\n",
      "Average difference: 0.006319315638393164\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad3defb325d4ba99cc0e6075354e8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112854a85a2d4d37b888478faf517365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - fear_female\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 348\n",
      "False: 2\n",
      "The total number of records with same predicted label: 348\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 348\n",
      "African-American average: 0.98368239402771\n",
      "European average: 0.9804046750068665\n",
      "Average difference: 0.00892819743603468\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b4d845aa484fe8b47fcc8d61ff11b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4bf3380b00465f9885949e5c54ba59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - joy_female\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 350\n",
      "The total number of records with same predicted label: 350\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 350\n",
      "African-American average: 0.9815054535865784\n",
      "European average: 0.9804233908653259\n",
      "Average difference: 0.007047549821436405\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e725e18e8649b390d5e92598fa2ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db79a25aec66412d862bacd6cadae389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - sadness_female\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 350\n",
      "The total number of records with same predicted label: 350\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 350\n",
      "African-American average: 0.9937953352928162\n",
      "European average: 0.9940715432167053\n",
      "Average difference: 0.0014520029071718454\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac09592b6f948de97c574078bba3f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8331be3ae540338df2995431420c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - non-emotion_male\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 34\n",
      "False: 6\n",
      "The total number of records with same predicted label: 34\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 34\n",
      "African-American average: 0.8616155982017517\n",
      "European average: 0.9314786791801453\n",
      "Average difference: 0.09137531369924545\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c93fe9124b4f548f3c9e59aa689628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b041236281471e884cda8313a14501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Set - non-emotion_female\n",
      "The model counts for predicting the same label for each race:\n",
      "True: 37\n",
      "False: 3\n",
      "The total number of records with same predicted label: 37\n",
      "The model predicted the same value for this many records: 0\n",
      "The model predicted a different value for this many records: 37\n",
      "African-American average: 0.9127255082130432\n",
      "European average: 0.9262598156929016\n",
      "Average difference: 0.07581301033496857\n",
      "-------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "race_compare('angry_male', df_male_angry_AA, df_male_angry_E)\n",
    "race_compare('fear_male', df_male_fear_AA, df_male_fear_E)\n",
    "race_compare('joy_male', df_male_joy_AA, df_male_joy_E)\n",
    "race_compare('sadness_male', df_male_sadness_AA, df_male_sadness_E)\n",
    "\n",
    "race_compare('angry_female', df_female_angry_AA, df_female_angry_E)\n",
    "race_compare('fear_female', df_female_fear_AA, df_female_fear_E)\n",
    "race_compare('joy_female', df_female_joy_AA, df_female_joy_E)\n",
    "race_compare('sadness_female', df_female_sadness_AA, df_female_sadness_E)\n",
    "\n",
    "race_compare('non-emotion_male', df_male_AA_non_emotion, df_male_E_non_emotion)\n",
    "race_compare('non-emotion_female', df_female_AA_non_emotion, df_female_E_non_emotion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
